{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Python Almanac\n",
    "\n",
    "The world of Python packages is adventurous and can be confusing at times.\n",
    "Here, I try to aggregate and showcase a diverse set of Python packages which have become useful at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Python\n",
    "\n",
    "Normally you should use your system's package manager.\n",
    "In case of problems, try [pyenv](https://github.com/pyenv/pyenv):\n",
    "\n",
    "```bash\n",
    "$ pyenv versions\n",
    "$ pyenv install <foo>\n",
    "$ pyenv global <foo>\n",
    "```\n",
    "\n",
    "This will install the specified Python version to `$(pyenv root)/versions`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing packages\n",
    "\n",
    "Python packages can be easily installed from [PyPI (Python Package Index)](https://pypi.org/):\n",
    "\n",
    "```bash\n",
    "$ pip install --user <package> (local install does not clash with system packages)\n",
    "```\n",
    "\n",
    "Using `--user` will install the package only for the current user. This is good if multiple users need different package versions, but can lead to redundant installations.\n",
    "\n",
    "To install from a git repository, use the following command:\n",
    "\n",
    "```bash\n",
    "$ pip install --user -U git+https://github.com/<user>/<repository>@<branch>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package management\n",
    "\n",
    "While packages can be installed globally or user-specific, it often makes sense to create project-specific virtual environments.\n",
    "\n",
    "This can be easily accomplished using [venv](https://docs.python.org/3/library/venv.html):\n",
    "\n",
    "```bash\n",
    "$ python -m venv my_venv\n",
    "$ . venv/bin/activate\n",
    "$ pip install <package>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Distribution\n",
    "\n",
    "Use `setuptools`.\n",
    "[poetry](https://github.com/sdispater/poetry) handles many otherwise slightly annoying things:\n",
    "```\n",
    "$ poetry init/add/install/run/publish\n",
    "```\n",
    "\n",
    "CI encapsulation: [tox](https://github.com/tox-dev/tox).\n",
    "\n",
    "Keeping track of version numbers can be achieved using [bump2version](https://github.com/c4urself/bump2version).\n",
    "\n",
    "Transform between various project file formats using [dephell](https://github.com/dephell/dephell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Setup testing using [pytest](https://github.com/pytest-dev/pytest). It has a wide range of useful features, such as fixtures (modularized per-test setup code) and test parametrization (quickly execute the same test for multiple inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/tests.py\n",
    "\n",
    "import os\n",
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.fixture(scope='session')\n",
    "def custom_directory(tmp_path_factory):\n",
    "    return tmp_path_factory.mktemp('workflow_test')\n",
    "\n",
    "\n",
    "def test_fixture_execution(custom_directory):\n",
    "    assert os.path.isdir(custom_directory)\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize('expression_str,result', [\n",
    "    ('2+2', 4), ('2*2', 4), ('2**2', 4)\n",
    "])\n",
    "def test_expression_evaluation(expression_str, result):\n",
    "    assert eval(expression_str) == result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest -v /tmp/tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linting/Formatting\n",
    "\n",
    "Linters and code formatters improve the quality of your Python code by conducting a static analysis and flagging issues.\n",
    "\n",
    "* [flake8](https://github.com/PyCQA/flake8): Catch various common errors and adhere to PEP8. Supports many [plugins](https://github.com/DmytroLitvinov/awesome-flake8-extensions).\n",
    "* [pylint](https://github.com/PyCQA/pylint): Looks for even more sources of code smell.\n",
    "* [black](https://github.com/psf/black): \"*the* uncompromising Python code formatter\".\n",
    "\n",
    "While there can be a considerable overlap between the tools' outputs, each offers its own advantages and they can typically be used together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling\n",
    "\n",
    "Code profiling tools are a great way of finding parts of your code which can be optimized.\n",
    "They come in various flavors:\n",
    "\n",
    "* [line_profiler](https://github.com/pyutils/line_profiler): which parts of the code require most execution time\n",
    "* [memory_profiler](https://github.com/pythonprofilers/memory_profiler): which parts of the code consume the most memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following script (note the `@profile` decorator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/script.py\n",
    "\n",
    "@profile\n",
    "def main():\n",
    "    # takes a long time\n",
    "    for _ in range(100_000):\n",
    "        1337**42\n",
    "\n",
    "    # requires a lot of memory\n",
    "    arr = [1] * 1_000_000\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kernprof -l -v -o /tmp/script.py.lprof /tmp/script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m memory_profiler /tmp/script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw python\n",
    "\n",
    "[ipdb](https://github.com/gotcha/ipdb) is useful Python commandline debugger.\n",
    "To invoke it, simply put `import ipdb; ipdb.set_trace()` in your code.\n",
    "Starting with Python 3.7, you can also write `breakpoint()`. This honors the `PYTHONBREAKPOINT` environment variable.\n",
    "To automatically start the debugger when an error occurs, run your script with `python -m ipdb -c continue <script>`.\n",
    "\n",
    "The debugger supports various commands:\n",
    "* p: print expression\n",
    "* pp: pretty print\n",
    "* n: next line in current function\n",
    "* s: execute current line and stop at next possible location (e.g. in function call)\n",
    "* c: continue execution\n",
    "* unt: execute until we reach greater line\n",
    "* l: list source (`l .`)\n",
    "* ll: whole source code of current function\n",
    "* b: breakpoint (`[ ([filename:]lineno | function) [, condition] ]`)\n",
    "* w/bt: print stack trace\n",
    "* u: move up the stack trace\n",
    "* d: move down the stack trace\n",
    "* h: help\n",
    "* q: quit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C++ extension:\n",
    "Open two windows: ipython, ldb (gdb)\n",
    "\n",
    "In [1]: !ps aux | grep -i ipython\n",
    "(lldb) attach --pid 1234\n",
    "(lldb) continue\n",
    "\n",
    "(lldb) breakpoint set -f myfile.cpp -l 400\n",
    "\n",
    "In [2]: run myscript.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sphinx, nbsphinx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging\n",
    "\n",
    "There are various built-in and third-party logging modules available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug('Helpful debug message')\n",
    "logger.error('oh no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciPy\n",
    "\n",
    "[SciPy](https://www.scipy.org/) is comprised of various popular Python modules which are for scientific computations.\n",
    "\n",
    "[Numpy](https://numpy.org/) can be used for a multitude of things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(size=(100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes\n",
    "\n",
    "Organizing your data in dataframes using [pandas](https://pandas.pydata.org/) makes nearly everything easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
    "df['group'] = np.random.choice(['G1', 'G2'], size=df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networkx\n",
    "\n",
    "[Networkx](https://github.com/networkx/networkx) is a wonderful library for conducting network analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.watts_strogatz_graph(100, 4, 0.1)\n",
    "print(nx.info(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.drawing.nx_agraph.graphviz_layout(graph, prog='neato', args='-Goverlap=scale')\n",
    "list(pos.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_clustering = nx.clustering(graph)\n",
    "list(node_clustering.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(\n",
    "    graph, pos,\n",
    "    node_size=100,\n",
    "    node_list=list(node_clustering.keys()),\n",
    "    node_color=list(node_clustering.values())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib\n",
    "\n",
    "[Matplotlib](https://matplotlib.org/) is the de facto standard plotting library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(data[:, 0], data[:, 1])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axis ticks can be formatted in a multitude of different [ways](https://matplotlib.org/api/ticker_api.html#tick-formatting).\n",
    "The most versatile way is probably `FuncFormatter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@FuncFormatter\n",
    "def my_formatter(x, pos):\n",
    "    return f'{x=}, {pos=}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.scatter(data[:, 0], data[:, 1])\n",
    "\n",
    "ax.xaxis.set_major_formatter(my_formatter)\n",
    "ax.yaxis.set_major_formatter(my_formatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seaborn\n",
    "\n",
    "[Seaborn](https://seaborn.pydata.org/) makes working with dataframes and creating commonly used plots accessible and comfortable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convert dataframe from wide to long format\n",
    "df_long = pd.melt(df, id_vars=['group'])\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_long, x='variable', y='value', hue='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statannot\n",
    "\n",
    "[Statannot](https://github.com/webermarcolivier/statannot) can be used to quickly add markers of significance to comparison plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statannot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(\n",
    "    data=df_long,\n",
    "    x='variable', y='value', hue='group',\n",
    "    order=['A', 'B', 'C'], hue_order=['G1', 'G2']\n",
    ")\n",
    "\n",
    "statannot.add_stat_annotation(\n",
    "    ax, plot='barplot',\n",
    "    data=df_long,\n",
    "    x='variable', y='value', hue='group',\n",
    "    order=['A', 'B', 'C'], hue_order=['G1', 'G2'],\n",
    "    box_pairs=[(('B', 'G1'), ('B', 'G2'))],\n",
    "    text_format='simple', test='Mann-Whitney'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brokenaxes\n",
    "\n",
    "[Brokenaxes](https://github.com/bendichter/brokenaxes) can be used to include outliers in a plot without messing up the axis range. Note that this can be quite misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brokenaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bax = brokenaxes.brokenaxes(ylims=((0, 20), (90, 110)))\n",
    "bax.boxplot([np.random.normal(10, size=100), np.random.normal(100, size=100)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusttext\n",
    "\n",
    "[Adjusttext](https://github.com/Phlya/adjustText) can help for plots with many labels which potentially overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = data[:40, :]\n",
    "fig, (ax_raw, ax_adj) = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "\n",
    "ax_raw.scatter(data_sub[:, 0], data_sub[:, 1])\n",
    "[ax_raw.annotate(f'{round(x, 1)},{round(y, 1)}', xy=(x, y)) for x, y in data_sub[:, [0, 1]]]\n",
    "\n",
    "ax_adj.scatter(data_sub[:, 0], data_sub[:, 1])\n",
    "adjust_text([ax_adj.annotate(f'{round(x, 1)},{round(y, 1)}', xy=(x, y)) for x, y in data_sub[:, [0, 1]]], arrowprops=dict(arrowstyle='->'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotnine\n",
    "\n",
    "While matplotlib's pyplot provides a similar plotting interface as MATLAB, [plotnine](https://github.com/has2k1/plotnine) implements a grammar of graphics and is (in ideology) based on R's [ggplot2](https://github.com/tidyverse/ggplot2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(plotnine.ggplot(df_long, plotnine.aes(x='variable', y='value', color='group')) +\n",
    "    plotnine.geom_boxplot() +\n",
    "    plotnine.facet_wrap('~group') +\n",
    "    plotnine.theme_minimal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Folium\n",
    "\n",
    "[Folium](https://github.com/python-visualization/folium) is a Python wrapper of the [Leaflet.js](https://leafletjs.com/) library to visualize dynamic maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.Map(\n",
    "    location=[np.random.uniform(40, 70), np.random.uniform(10, 30)], zoom_start=7,\n",
    "    width=500, height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High performance\n",
    "\n",
    "When dealing with large amounts of data or many computations, it can make sense to optimize hotspots in C++ or use specialized libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask\n",
    "\n",
    "[Dask](https://github.com/dask/dask) provides a Panda's like interface to high-performance dataframes which support out-of-memory processing, cluster distribution, and more.\n",
    "It is particularly useful when the dataframe does not fit in RAM anymore. Common operations operate on chunks of the dataframe and are only executed when explicitly requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.normal(size=(1_000_000, 2)), columns=['A', 'B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.from_pandas(df, npartitions=4)\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['A'] + ddf['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ddf['A'] + ddf['B']).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaex\n",
    "\n",
    "[Vaex](https://github.com/vaexio/vaex) fills a similar niche as dask and makes working with out-of-core dataframe easy.\n",
    "It has a slightly more intuitive interface and offers many cool visualizations right out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaex as vx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf = vx.from_pandas(df)\n",
    "vdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf['A'] + vdf['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf.plot(vdf['A'], vdf['B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joblib\n",
    "\n",
    "[Joblib](https://github.com/joblib/joblib) makes executing functions in parallel very easy and removes boilerplate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heavy_function(i):\n",
    "    print(f'{i=}')\n",
    "    time.sleep(random.random())\n",
    "    return i ** i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.Parallel(n_jobs=2)([joblib.delayed(heavy_function)(i) for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swifter\n",
    "\n",
    "Choosing the correct way of parallelizing your computations can be non-trivial. [Swifter](https://github.com/jmcarpenter2/swifter) tries to automatically select the most suitable one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big = pd.DataFrame({\n",
    "    'A': np.random.randint(0, 100, size=1_000_000)\n",
    "})\n",
    "df_big.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df_big['A'].apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df_big['A'].swifter.apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bioinformatics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyRanges\n",
    "\n",
    "[PyRanges](https://github.com/biocore-ntnu/pyranges) makes working with genomic ranges easy as pie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyranges as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exons = pr.data.exons()\n",
    "df_exons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locus = pr.PyRanges(pd.DataFrame({'Chromosome': ['chrX'], 'Start': [1_400_000], 'End': [1_500_000]}))\n",
    "df_locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exons.overlap(df_locus).df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obonet\n",
    "\n",
    "[Obonet](https://github.com/dhimmel/obonet) is a library for working with (OBO-formatted) ontologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/DiseaseOntology/HumanDiseaseOntology/raw/master/src/ontology/HumanDO.obo'\n",
    "graph = obonet.read_obo(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(graph.nodes(data=True))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics/Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statsmodels\n",
    "\n",
    "[Statsmodels](https://github.com/statsmodels/statsmodels) helps with statistical modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame({\n",
    "    'X': np.random.normal(size=100)\n",
    "})\n",
    "\n",
    "df_data['Y'] = 1.3 * df_data['X'] + 4.2\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols('Y ~ X', data=df_data)\n",
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pingouin\n",
    "\n",
    "[Pingouin](https://github.com/raphaelvallat/pingouin) provides additional statistical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.normality(np.random.normal(size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.normality(np.random.uniform(size=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scitkit-learn\n",
    "\n",
    "[Scikit-learn](https://github.com/scikit-learn/scikit-learn) facilitates machine learning in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn offers various plugins which deal with common issues encountered while modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) provides various re-sampling techniques when the dataset has annoying class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub, y_sub = X[:60, :], y[:60]\n",
    "X_resampled, y_resampled = ros.fit_resample(X_sub, y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sub:', sorted(collections.Counter(y_sub).items()))\n",
    "print('resampled:', sorted(collections.Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Category_encoders](https://github.com/scikit-learn-contrib/category_encoders) helps with converting categorical variables to numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.random.choice(['A', 'B'], size=10)\n",
    "df_cat = pd.DataFrame({\n",
    "    'original_class': tmp,\n",
    "    'feature01': tmp\n",
    "})\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_encoders.OneHotEncoder(cols=['feature01']).fit_transform(df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Yellowbrick](https://github.com/DistrictDataLabs/yellowbrick) makes a multitude of visual diagnostic tools readily accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(clf)\n",
    "visualizer.score(X, y)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Bindings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pybind11\n",
    "\n",
    "[Pybind11](https://github.com/pybind/pybind11) makes writing bindings between Python and C++ enjoyable. In combination with [cppimport](https://github.com/tbenthompson/cppimport) some might even call it fun.\n",
    "It is possible to implement [custom typecasters](https://pybind11.readthedocs.io/en/stable/advanced/cast/custom.html) to support bindings for arbitrary objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cpp_source.cpp\n",
    "\n",
    "#include <pybind11/pybind11.h>\n",
    "\n",
    "namespace py = pybind11;\n",
    "\n",
    "\n",
    "int square(int x) {\n",
    "    return x * x;\n",
    "}\n",
    "\n",
    "PYBIND11_MODULE(cpp_source, m) {\n",
    "    m.def(\n",
    "        \"square\", &square,\n",
    "        py::arg(\"x\") = 1\n",
    "    );\n",
    "}\n",
    "\n",
    "/*\n",
    "<%\n",
    "setup_pybind11(cfg)\n",
    "cfg['compiler_args'] = ['-std=c++11']\n",
    "%>\n",
    "*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cppimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_source = cppimport.imp('cpp_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_source.square(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nbstripout\n",
    "\n",
    "Commiting Jupyter notebooks to CVS (e.g. git) can be annoying due to non-code properties being saved.\n",
    "[Nbstripout](https://github.com/kynan/nbstripout) strips all of those away and can be run automatically for each committed notebook by executing `nbstripout --install` once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo\n",
    "\n",
    "* Validate your config files using [schemas](https://github.com/Julian/jsonschema/).\n",
    "* Design your pipelines using [Snakemake](https://bitbucket.org/snakemake/snakemake).\n",
    "* moviepy\n",
    "* https://github.com/tqdm/tqdm\n",
    "* https://github.com/pyca/cryptography\n",
    "* https://github.com/jmoiron/humanize\n",
    "* numba\n",
    "* pythran\n",
    "* https://github.com/cloudpipe/cloudpickle\n",
    "* jupytext\n",
    "* dfply(/plydata)\n",
    "* tensorflow\n",
    "* filprofiler\n",
    "* https://github.com/mitmproxy/mitmproxy\n",
    "* https://github.com/secdev/scapy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
