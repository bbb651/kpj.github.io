{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Eurostat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from r_wrapper import eurostat\n",
    "\n",
    "from bioinf_common.plotting import get_distinct_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving geographical information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NUTS classification subdivides each member state into regions at three different levels, covering NUTS 1, 2 and 3 from larger to smaller areas (https://ec.europa.eu/eurostat/web/nuts/background).\n",
    "Eurostat provides this geographical data in various formats (https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units, looks for \"NUTS\").\n",
    "\n",
    "The filename of each dataset follows a specific format:  `<theme>_<spatialtype>_<resolution>_<year>_<projection>_<subset>.<extension>` (check https://ec.europa.eu/eurostat/cache/GISCO/distribution/v2/nuts/nuts-2016-files.html for more information).\n",
    "\n",
    "To make things easier, we use the `eurostat` package to retrieve this data automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# hide download progress output\n",
    "null = open(os.devnull, 'wb')\n",
    "sys.stderr = null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = eurostat.get_eurostat_geospatial(output_class='sf', resolution=60, nuts_level=2, year=2016)\n",
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "sys.stderr = sys.__stderr__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a feeling for the data, we can plot the geographical composition of an arbitrary country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gplt.polyplot(df_geo[df_geo['CNTR_CODE'] == 'DE'])\n",
    "ax.set_aspect(1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving statistical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eurostat is a great source for data related to Europe.\n",
    "An overview of the main tables can be found on https://ec.europa.eu/eurostat/web/regions/data/main-tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eurostat.search_eurostat('age').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [\n",
    "    'tgs00101',  # life expectancy\n",
    "    'tgs00026',  # exposable income\n",
    "    'tgs00036',  # primary income\n",
    "    'tgs00010',  # unemployment rate\n",
    "    'tgs00112',  # touristic bed number\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and aggregate data\n",
    "\n",
    "To make the subsequent analysis easier, we download all data at once and store it in a single dataframe.\n",
    "Additionally, we store associated meta data in another dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# hide download progress output\n",
    "null = open(os.devnull, 'wb')\n",
    "sys.stderr = null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "meta_list = []\n",
    "\n",
    "for dataset in tqdm(dataset_list):\n",
    "    # get dataset description\n",
    "    dataset_name = eurostat.label_eurostat_tables(dataset)[0]\n",
    "    print(f'Parsing {dataset} ({dataset_name})')\n",
    "    \n",
    "    # retrieve data\n",
    "    df_data = eurostat.get_eurostat(dataset, time_format='raw')\n",
    "    df_data = eurostat.label_eurostat(df_data, code=['geo'], fix_duplicated=True)\n",
    "\n",
    "    # index rows\n",
    "    common_columns = ['geo_code', 'geo']\n",
    "    df_data['idx'] = df_data[common_columns].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "    \n",
    "    # identify meta information\n",
    "    info_columns = set(df_data.columns) - set(common_columns) - {'idx', 'time', 'values', 'info', 'info_short'}\n",
    "    \n",
    "    meta_cols = [';'.join(f'{k}={row._asdict()[k]}' for k in sorted(row._asdict().keys()) if k != 'Index') for row in df_data[info_columns].itertuples()]\n",
    "    meta_idx, meta_label = pd.factorize(meta_cols)\n",
    "    \n",
    "    df_data['meta'] = [f'{dataset}_{time}_{x}' for x, time in zip(meta_idx, df_data['time'])]\n",
    "\n",
    "    # pivot data\n",
    "    df_piv = df_data.pivot(index='idx', columns='meta', values='values')\n",
    "    \n",
    "    # store data\n",
    "    df_list.append(df_piv)\n",
    "\n",
    "    meta_list.extend([{\n",
    "        'dataset': dataset,\n",
    "        'name': dataset_name,\n",
    "        'meta_idx': idx,\n",
    "        'meta_label': label,\n",
    "    } for idx, label in zip(np.unique(meta_idx), meta_label)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row corresponds to a geographic region, and each column to a certain statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "sys.stderr = sys.__stderr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat(df_list, axis=1)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra information for each column is stored in an additional dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.DataFrame(meta_list)\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(col_name, extended=False):\n",
    "    dataset, time, idx = col_name.split('_')\n",
    "    res = df_meta[(df_meta['dataset'] == dataset) & (df_meta['meta_idx'] == int(idx))]\n",
    "    assert res.shape[0] == 1\n",
    "    res = res.iloc[0]\n",
    "    \n",
    "    if extended:\n",
    "        return f'{res[\"name\"]}\\n({res[\"meta_label\"]})'\n",
    "    else:\n",
    "        return res[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "To get a rough overview of the data, we can plot the clustered correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_all.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nan_datasets = set(df_corr.dropna(axis=0).index) & set(df_corr.dropna(axis=1).columns)\n",
    "df_corr = df_corr.loc[non_nan_datasets, non_nan_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign unique color to each data source\n",
    "cluster_names = df_all.columns.str.split('_').str[0].unique()\n",
    "cluser_colors = get_distinct_colors(len(cluster_names))\n",
    "cluster_map = {n: c for n, c in zip(cluster_names, cluser_colors)}\n",
    "cluster_colors = pd.DataFrame([(col, cluster_map[col.split('_')[0]]) for col in df_all.columns]).set_index(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.clustermap(\n",
    "    df_corr,\n",
    "    xticklabels=False, yticklabels=False,\n",
    "    cmap='vlag_r',\n",
    "    row_colors=cluster_colors, col_colors=cluster_colors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "In order to combine both geographical and statistical data, we merge the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['geo_code'] = [idx.split('_')[0] for idx in df_all.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_geo.merge(df_all, left_on='NUTS_ID', right_on='geo_code')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and dissolve it to reach a resolution which leads to a nice visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_diss = df_merged.dissolve(by='CNTR_CODE', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We visualize the data using choropleth maps. By doing so, each geographical region is colored according to a statistic of interest.\n",
    "\n",
    "In the following, we will use a single entry from each downloaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 2016\n",
    "hue_selection = [f'{row.dataset}_{time}_{row.meta_idx}' \n",
    "                 for row in df_meta.groupby('dataset').apply(lambda x: x.sample(n=1)).itertuples()]\n",
    "hue_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single country\n",
    "\n",
    "We can get a precise overview of individual regions within a single country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(np.ceil(np.sqrt(len(hue_selection))))  # size of plot grid\n",
    "\n",
    "fig, axes = plt.subplots(nrows=size, ncols=size, figsize=(20, 20))\n",
    "[ax.axis('off') for ax in axes.ravel()]\n",
    "\n",
    "for hue, ax in zip(hue_selection, axes.ravel()):\n",
    "    sub = df_merged[(df_merged['CNTR_CODE'] == 'DE')]\n",
    "    \n",
    "    gplt.choropleth(sub, hue=hue, legend=True, ax=ax)\n",
    "    ax.set_aspect(1.4)\n",
    "    ax.set_title(get_meta(hue), fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Europe\n",
    "\n",
    "To get a more global picture, we can also plot the aggregated data per country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hue in hue_selection:\n",
    "    ax = gplt.choropleth(\n",
    "        df_diss, hue=hue,\n",
    "        legend=True, #k=5,\n",
    "        figsize=(16, 12),\n",
    "        extent=(-25, 30, 45, 75),  # (min_longitude, min_latitude, max_longitude, max_latitude)\n",
    "    )\n",
    "    ax.set_aspect(1.4)\n",
    "    ax.set_title(get_meta(hue))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
